{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization.py loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import re\n",
    "from Visualization import *\n",
    "from hough_transform import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = os.path.join('Lane_Parameters', 'Lane_Videos')\n",
    "lane_dir = os.path.join('Lane_Parameters', 'Lane_Parameters')\n",
    "def get_video(video_num):\n",
    "    return os.path.join(video_dir, 'IMG_'+ video_num + '.MOV')\n",
    "\n",
    "\n",
    "def get_lanes(video_num, frame_num, factor = 1):\n",
    "    \n",
    "    p = re.compile('[0-9]*,[0-9]*')\n",
    "    file = open(os.path.join(lane_dir, video_num, str(frame_num) + '.txt'))\n",
    "    lanes = []\n",
    "\n",
    "    for line in file:\n",
    "        points = p.findall(line)\n",
    "        for i, point in enumerate(points):\n",
    "            points[i] = tuple(map(int, point.split(',')))\n",
    "            points[i] = int(points[i][0]/factor), int(points[i][1]/factor)\n",
    "        \n",
    "        lanes.append(points)\n",
    "    file.close()\n",
    "    return lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "video_num = '0250'\n",
    "vid = cv.VideoCapture(get_video(video_num))\n",
    "\n",
    "frame_num = 1000\n",
    "\n",
    "for i in range(frame_num):\n",
    "    sucess, orignal_frame = vid.read()\n",
    "    if not sucess:\n",
    "        break\n",
    "vid.release()\n",
    "\n",
    "\n",
    "img = orignal_frame.copy()\n",
    "\n",
    "factor = 2\n",
    "\n",
    "img = cv.resize(img,(0,0), fx=1/factor, fy=1/factor)\n",
    "\n",
    "PLTdraw(orignal_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dots(img, dots, radius=2, color=(255,0,0), thickness=2):\n",
    "    for dot in dots:\n",
    "        img = cv.circle(img, dot, 2, color, thickness)\n",
    "    return img\n",
    "\n",
    "def draw_lanes(img_org, lanes, radius=3, colorLst=None, thickness=1):\n",
    "    img = img_org.copy()\n",
    "    for lane in lanes:\n",
    "        color = None\n",
    "        if colorLst is None:\n",
    "            color = random_color()\n",
    "        img = draw_dots(img, lane, radius, color, thickness)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "\n",
    "def random_color():\n",
    "    rand.seed(10)\n",
    "    return rand.randint(0,255), rand.randint(0,255), rand.randint(0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lanes = get_lanes(video_num, frame_num, factor)\n",
    "doted = draw_lanes(img, lanes)\n",
    "PLTdraw(doted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr2gray(bgr):\n",
    "    return (bgr[:,:,2]*0.2126 + bgr[:,:,1]*0.7152 + bgr[:,:,0]*0.0722)\n",
    "\n",
    "grayed = bgr2gray(img)\n",
    "plt.imshow(grayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Edge Detector \n",
    "By Tharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel(grayed_frame, thresh=100):\n",
    "    \n",
    "    #Implementing image smoothing\n",
    "    rows = grayed_frame.shape[0]\n",
    "    cols = grayed_frame.shape[1]\n",
    "    \n",
    "    kernel = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])/9.0\n",
    "    mag_smooth = np.zeros((rows,cols))\n",
    "    \n",
    "    #pad with zeros on the border for full blurring of image\n",
    "    padded_gray = np.zeros((rows + 2, cols + 2))\n",
    "    padded_gray[1:-1, 1:-1] = grayed_frame\n",
    "    \n",
    "    for x in range(rows):\n",
    "        for y in range(cols):\n",
    "            mag_smooth[x][y] = (kernel * padded_gray[x:x+3, y:y+3]).sum()\n",
    "    \n",
    "    ##Implementing sobel edge detector\n",
    "    Gx = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "    Gy = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "    \n",
    "    mag_G = np.zeros((rows,cols))\n",
    "    \n",
    "    for i in range(1, rows - 1):\n",
    "        for j in range(1, cols - 1):\n",
    "            sumx = (Gx * mag_smooth[i-1:i+2, j-1:j+2]).sum()\n",
    "            sumy = (Gy * mag_smooth[i-1:i+2, j-1:j+2]).sum()\n",
    "            mag_G[i][j] = np.sqrt(sumx**2 + sumy**2)\n",
    "            \n",
    "    threshed = (mag_G > thresh).astype(np.uint8)\n",
    "    \n",
    "    binary_lut = np.zeros(256).astype(\"uint8\")\n",
    "    binary_lut[1] = 255\n",
    "    \n",
    "    threshed = cv.LUT(threshed.astype(np.uint8), binary_lut)\n",
    "    \n",
    "    return threshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices=None):\n",
    "    # Define a blank matrix that matches the image height/width\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    img = img.astype('unit8')\n",
    "    \n",
    "    # Retrieve the number of color channels of the image\n",
    "    # Will be 3 in this case because image is RGB\n",
    "    if(len(img.shape)<3):\n",
    "        channel_count = 1\n",
    "    else:\n",
    "        channel_count = img.shape[2]\n",
    "    \n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    if vertices is None:\n",
    "        vertices = np.array([\n",
    "            (0, h),\n",
    "            (w/2, h/2),\n",
    "            (w, h),\n",
    "        ], np.int8).astype('uint8')\n",
    "    \n",
    "    # Create a match color with the same color channel counts for fillPoly to know how to fill the mask\n",
    "    match_mask_color = (255,) * channel_count\n",
    "      \n",
    "    # Fills the area bounded by the polygon with vertices in vertices\n",
    "    cv.fillPoly(mask, vertices, match_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "edged = sobel(grayed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = edged.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h, w = edged.shape\n",
    "# region_of_interest_vertices = np.array([\n",
    "#     (0, h),\n",
    "#     (w/2, h/2),\n",
    "#     (w, h),\n",
    "# ])\n",
    "# region_of_interest_vertices = region_of_interest_vertices.astype('uint8')\n",
    "\n",
    "cropped_image = region_of_interest(edged)\n",
    "\n",
    "plt.imshow(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator, point_stack = Hough_lines(cropped_image, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_coord = [] #To store the coordinates of the lines\n",
    "# point_stack = point_stack[1:]\n",
    "overlay = img.copy()\n",
    "for i in point_stack:\n",
    "    points = hough_intersect(i[0], i[1], img)\n",
    "    if(len(points)!=2):\n",
    "        continue\n",
    "    points_coord.append([list(point) for point in points])\n",
    "    cv.line(overlay, points[0], points[1], (0, 0, 255))\n",
    "PLTdraw(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_contrast(img):\n",
    "    [0, 255, 255, ...]\n",
    "                \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
